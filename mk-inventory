#!/usr/bin/env python

import argparse
from collections import defaultdict
from StringIO import StringIO
import yaml
import os
import os.path
import itertools
import logging
logging.basicConfig(level=logging.INFO,
                    format='%(levelname)-9s %(message)s')
logger = logging.getLogger(__name__)
_DESCRIPTION = """
Generate a valid Ansible inventory file and associated host_vars and group_vars.
You need to provide a name for the virtual cluster, and SSH-able IP addresses.

The inventory will be written to stdout and log messages to stderr.

Example:

  ./mk-inventory -n foo 192.168.1.10{1,2,3,4,5} >inventory.txt
"""

def get_opts():
    p = argparse.ArgumentParser(
        description=_DESCRIPTION,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    p.add_argument('-n', '--name', metavar='TEXT', default='myvc',
                   help='The name for the virtual cluster')
    p.add_argument('addresses', nargs='+', metavar='IP',
                   help='IP addresses of the cluster')

    return p.parse_args()

class Node(object):

    def __init__(self, name, address):
        self._name = name
        self._address = address
        self._variables = dict()

    def add_var(self, key, value):
        """Add a variable and value to a node. This will show up in the host_vars file

        :param key: the name of the variable
        :type key: :class:`str`
        :param value: the value of the variable
        :type value: anything that is valid YAML
        """

        if key in self._variables:
            logger.warning('Overwriting previous definition of {} = {}'\
                           .format(key, self._variables[key]))

        self._variables[key] = value

    @property
    def name(self):
        """The name of this node
        :rtype: :class:`str`
        """
        return self._name

    @property
    def address(self):
        """The IP address of this node
        :rtype: :class:`str`
        """
        return self._address

    def as_host_vars(self):
        """generate the ``host_vars`` representation of this node

        :rtype: :class:`str`
        """

        d = dict(
            ansible_ssh_host=self.address
        )
        d.update(self._variables)
        
        return yaml.dump(d, default_flow_style=False)


class Inventory(object):

    def __init__(self, groups=None):
        self._groups = groups or defaultdict(list)
        self._nodes = set()


    def add_node(self, group, node):
        """Adds a node to a group

        :param group: the group name (creates if not already present)
        :type group: :class:`str`
        :param node: the node to be inserted in ``group``
        :param node: :class:`Node`
        """

        if node not in self._groups[group]:
            self._groups[group].append(node)

        self._nodes.add(node)


    def add_group_to(self, src, target):
        """Adds all the nodes in ``src`` to ``target``
        """

        for node in self._groups[src]:
            self.add_node(target, node)


    def as_ini(self):
        """Generates the ansible inventory file in ini text file format (the usual)
        
        :returns: the inventory as usable by Ansible
        :rtype: :class:`str`
        """

        s = StringIO()
        for name, nodes in self._groups.iteritems():
            s.write('[{}]\n'.format(name))
            for n in nodes:
                s.write('{}\n'.format(n.name))
            s.write('\n')

        v = s.getvalue()
        s.close()
        return v


    def write_host_vars(self, prefix='.'):
        """Write the host_vars for each node in the inventory.

        :param prefix: where the ``host_vars`` will be written (default is current directory)
        """

        funcs = [os.path.relpath,
                 os.path.abspath,
                 os.path.expanduser,
                 os.path.expandvars]

        real_prefix = reduce(lambda path, f: f(path),
                             reversed(funcs),
                             prefix
                             )


        host_vars = os.path.join(real_prefix, 'host_vars')

        if os.path.exists(host_vars) and not os.path.isdir(host_vars):
            msg = '{} exists and is not a directory'.format(host_vars)
            logger.critical(msg)
            raise ValueError(msg)

        if not os.path.exists(host_vars):
            logger.warning('Creating directory {}'.format(host_vars))
            os.makedirs(host_vars)

        logger.info('Writing host_vars to {}'.format(host_vars))
        for node in self._nodes:
            path = os.path.join(host_vars, '{}'.format(node.name))
            yml  = node.as_host_vars()
            logger.info('Writing {}'.format(path))
            logger.debug('Writing to {} {}'.format(path, yml))

            if os.path.exists(path):
                logger.warning('Overwriting {}'.format(path))


            with open(path, 'w') as fd:
                fd.write(yml)


def mk_nodes(vcname, addresses):
    """Creates the :class:`Node`s

    :param vcname: name of the virtual cluster
    :type vcname: :class:`str`
    :param addresses: the ip addresses of the nodes
    :type addresses: :class:`list` of :class:`str`
    :returns: the Nodes
    :rtype: :class:`list` of :class:`Node`
    """

    nodes = list()
    for i, address in enumerate(addresses):
        name = '{name}{i}'.format(name=vcname, i=i)
        n = Node(name, address)
        nodes.append(n)

    return nodes



# There are several important groups used
#
# - zookeeper: the zookeeper nodes
# - namenodes: the nodes on which the HDFS namenodes (primary and backup) run
# - journalnodes: the nodes on which the HDFS journalnodes run
# - historyservers: the nodes on which the history server runs
# - resourcemanagers: the nodes on which the YARN resourcemanagers run
# - datanodes: the nodes which are used as compute nodes
# - frontends: nodes on which users should log into
# - hadoopnodes: a metagroup consisting of all nodes running hadoop, yarn, or other analytics software
# - monitor: the nodes on which the  monitoring software (eg Ganglia) is installed
#
#
# There are currently requirements on the number of nodes in each group.
# Additionally, as parameterizing these assignments is not currently
# supported, we'll just hardcode them here.
#
# The one that is intended to scale dynamically right now is the number
# of compute nodes, so you'll notice the absence of =_N_DATANODES= below.

_N_ZOOKEEPERS = 1
_N_NAMENODES = 1
_N_JOURNALNODES = 1
_N_HISTORYSERVERS = 1
_N_RESOURCEMANAGERS = 1
_N_FRONTENDS = 1
_N_MONITORS = 1


# Creating the Inventory
#
# Since the nodes is the virtual cluster are assumed to be identical the
# partitioning is arbitrary. We choose to iterate over the available nodes
# assigning each to the required group in a semi-round-robin fashion.



def create_inventory(nodes):
    """Assign the nodes to various groups and return the inventory

    :param nodes: the nodes
    :type nodes: :class:`list` of :class:`Node`
    :returns: the inventory
    :rtype: :class:`Inventory`
    """

    inventory = Inventory()

    assert len(nodes) >= _N_ZOOKEEPERS
    for i in xrange(_N_ZOOKEEPERS):
        node = nodes[i]
        node.add_var('zookeeper_id', i + 1) # need to start with 1
        inventory.add_node('zookeepernodes', node)

    assert len(nodes) >= _N_NAMENODES
    for i in xrange(_N_NAMENODES):
        node = nodes[i]
        inventory.add_node('namenodes', node)
    inventory.add_group_to('namenodes', 'hadoopnodes')

    assert len(nodes) >= _N_JOURNALNODES
    for i in xrange(_N_JOURNALNODES):
        node = nodes[i]
        inventory.add_node('journalnodes', node)
    inventory.add_group_to('journalnodes', 'hadoopnodes')

    assert len(nodes) >= _N_HISTORYSERVERS
    for i in xrange(_N_HISTORYSERVERS):
        node = nodes[i]
        inventory.add_node('historyservernodes', node)
    inventory.add_group_to('historyservernodes', 'hadoopnodes')

    assert len(nodes) >= _N_RESOURCEMANAGERS
    for i in xrange(_N_RESOURCEMANAGERS):
        node = nodes[i]
        inventory.add_node('resourcemanagernodes', node)
    inventory.add_group_to('resourcemanagernodes', 'hadoopnodes')

    assert len(nodes) >= _N_FRONTENDS
    for i in xrange(_N_FRONTENDS):
        node = nodes[i]
        inventory.add_node('frontendnodes', node)

    assert len(nodes) >= _N_MONITORS
    for i in xrange(_N_MONITORS):
        node = nodes[i]
        inventory.add_node('monitornodes', node)

    for node in nodes:
        inventory.add_node('datanodes', node)
    inventory.add_group_to('datanodes', 'hadoopnodes')


    return inventory


def main():
    opts = get_opts()
    nodes = mk_nodes(opts.name, opts.addresses)
    inventory = create_inventory(nodes)
    inventory.write_host_vars()
    print inventory.as_ini()

if __name__ == '__main__':
    main()
